#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
æµ‹è¯•WaveletHeadå’ŒISWTé‡æ„åŠŸèƒ½

éªŒè¯ç‚¹ï¼š
1. ISWTReconstructioné‡æ„ç²¾åº¦
2. WaveletHeadè¾“å‡ºå½¢çŠ¶æ­£ç¡®æ€§
3. ç«¯åˆ°ç«¯å°æ³¢åŸŸå¯¹ç§°æ¶æ„
"""

import torch
import torch.nn as nn
import sys
import os

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from layers.WaveletEmbed import SWTDecomposition, ISWTReconstruction, WaveletPatchEmbedding
from models.TimeLLM import WaveletHead, FlattenHead

print("=" * 80)
print("æµ‹è¯•1: ISWTé‡æ„ç²¾åº¦éªŒè¯")
print("=" * 80)

# æµ‹è¯•å‚æ•°
batch_size = 4
num_vars = 7
seq_len = 512
level = 3
wavelet = 'db4'

# æ£€æŸ¥GPU
device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
print(f"ä½¿ç”¨è®¾å¤‡: {device}")

# åˆ›å»ºæµ‹è¯•æ•°æ®
x_original = torch.randn(batch_size, num_vars, seq_len, device=device)
print(f"\nåŸå§‹ä¿¡å·: {x_original.shape}")

# æ­£å‘SWTåˆ†è§£
swt = SWTDecomposition(wavelet=wavelet, level=level).to(device)
coeffs = swt(x_original)
print(f"SWTåˆ†è§£å: {coeffs.shape} (4ä¸ªé¢‘æ®µ)")

# é€†ISWTé‡æ„
iswt = ISWTReconstruction(wavelet=wavelet, level=level).to(device)
x_reconstructed = iswt(coeffs)
print(f"ISWTé‡æ„å: {x_reconstructed.shape}")

# è®¡ç®—é‡æ„è¯¯å·®
reconstruction_error = torch.abs(x_original - x_reconstructed).mean().item()
max_error = torch.abs(x_original - x_reconstructed).max().item()
print(f"\né‡æ„ç²¾åº¦:")
print(f"  å¹³å‡ç»å¯¹è¯¯å·®: {reconstruction_error:.8f}")
print(f"  æœ€å¤§ç»å¯¹è¯¯å·®: {max_error:.8f}")

if reconstruction_error < 1e-5:
    print("  âœ… é‡æ„ç²¾åº¦ä¼˜ç§€ (è¯¯å·® < 1e-5)")
elif reconstruction_error < 1e-3:
    print("  âš ï¸  é‡æ„ç²¾åº¦è‰¯å¥½ (è¯¯å·® < 1e-3)")
else:
    print("  âŒ é‡æ„ç²¾åº¦è¾ƒå·®ï¼Œè¯·æ£€æŸ¥å®ç°")

print("\n" + "=" * 80)
print("æµ‹è¯•2: WaveletHeadè¾“å‡ºå½¢çŠ¶éªŒè¯")
print("=" * 80)

# WaveletHeadå‚æ•°
d_ff = 256
patch_nums = 64
pred_len = 96

# åˆ›å»ºWaveletHead
wavelet_head = WaveletHead(
    n_vars=num_vars,
    d_model=d_ff,
    patch_nums=patch_nums,
    pred_len=pred_len,
    level=level,
    wavelet=wavelet,
    head_dropout=0.1
).to(device)

# æ¨¡æ‹ŸLLMéšçŠ¶æ€è¾“å…¥
llm_hidden = torch.randn(batch_size, num_vars, d_ff, patch_nums, device=device)
print(f"\nLLMéšçŠ¶æ€è¾“å…¥: {llm_hidden.shape}")

# å‰å‘ä¼ æ’­
pred = wavelet_head(llm_hidden)
print(f"WaveletHeadè¾“å‡º: {pred.shape}")

# éªŒè¯è¾“å‡ºå½¢çŠ¶
expected_shape = (batch_size, num_vars, pred_len)
if pred.shape == expected_shape:
    print(f"âœ… è¾“å‡ºå½¢çŠ¶æ­£ç¡®: {pred.shape} == {expected_shape}")
else:
    print(f"âŒ è¾“å‡ºå½¢çŠ¶é”™è¯¯: {pred.shape} != {expected_shape}")

# éªŒè¯è¾“å‡ºæ•°å€¼æœ‰æ•ˆæ€§
if torch.isnan(pred).any() or torch.isinf(pred).any():
    print("âŒ è¾“å‡ºåŒ…å«NaNæˆ–Inf")
else:
    print("âœ… è¾“å‡ºæ•°å€¼æœ‰æ•ˆ")
    print(f"  å‡å€¼: {pred.mean().item():.6f}")
    print(f"  æ ‡å‡†å·®: {pred.std().item():.6f}")
    print(f"  æœ€å°å€¼: {pred.min().item():.6f}")
    print(f"  æœ€å¤§å€¼: {pred.max().item():.6f}")

print("\n" + "=" * 80)
print("æµ‹è¯•3: WaveletHead vs FlattenHead å‚æ•°é‡å¯¹æ¯”")
print("=" * 80)

# FlattenHead
head_nf = d_ff * patch_nums
flatten_head = FlattenHead(
    n_vars=num_vars,
    nf=head_nf,
    target_window=pred_len,
    head_dropout=0.1
).to(device)

# å‚æ•°é‡ç»Ÿè®¡
wavelet_params = sum(p.numel() for p in wavelet_head.parameters())
flatten_params = sum(p.numel() for p in flatten_head.parameters())

print(f"\nWaveletHead å‚æ•°é‡: {wavelet_params:,}")
print(f"FlattenHead å‚æ•°é‡: {flatten_params:,}")
print(f"å‚æ•°é‡æ¯”ä¾‹: {wavelet_params / flatten_params:.2f}x")

# æµ‹è¯•FlattenHeadè¾“å‡º
flatten_pred = flatten_head(llm_hidden)
print(f"\nFlattenHeadè¾“å‡º: {flatten_pred.shape}")

if flatten_pred.shape == pred.shape:
    print("âœ… ä¸¤ç§Headè¾“å‡ºå½¢çŠ¶ä¸€è‡´ï¼Œå¯ä»¥æ— ç¼æ›¿æ¢")
else:
    print("âŒ è¾“å‡ºå½¢çŠ¶ä¸ä¸€è‡´")

print("\n" + "=" * 80)
print("æµ‹è¯•4: ç«¯åˆ°ç«¯å°æ³¢åŸŸå¯¹ç§°æ¶æ„")
print("=" * 80)

print("\nå®Œæ•´æµç¨‹:")
print("  è¾“å…¥æ—¶åº (B, N, T)")
print("    â†“ WaveletPatchEmbedding (SWTåˆ†è§£ + Patching)")
print("  Patch embeddings (B*N, num_patches, d_model)")
print("    â†“ LLMå¤„ç†")
print("  LLMéšçŠ¶æ€ (B, N, d_ff, patch_nums)")
print("    â†“ WaveletHead (æŠ•å½±åˆ°å°æ³¢ç³»æ•°)")
print("  å°æ³¢ç³»æ•° (B, N, pred_len, 4é¢‘æ®µ)")
print("    â†“ ISWTé‡æ„")
print("  é¢„æµ‹æ—¶åº (B, N, pred_len)")

# æ¨¡æ‹Ÿå®Œæ•´æµç¨‹
print("\næ‰§è¡Œå®Œæ•´æµç¨‹...")

# Step 1: è¾“å…¥æ—¶åº
x_input = torch.randn(batch_size, num_vars, seq_len, device=device)
print(f"1. è¾“å…¥æ—¶åº: {x_input.shape}")

# Step 2: WaveletPatchEmbedding
patch_embed = WaveletPatchEmbedding(
    d_model=32,
    patch_len=16,
    stride=8,
    wavelet=wavelet,
    level=level,
    dropout=0.1
).to(device)
patches, n_vars = patch_embed(x_input)
print(f"2. Patch embeddings: {patches.shape}, n_vars={n_vars}")

# Step 3: æ¨¡æ‹ŸLLMå¤„ç†ï¼ˆè¿™é‡Œç›´æ¥reshapeåˆ°éœ€è¦çš„å½¢çŠ¶ï¼‰
# å®é™…ä¸­ä¼šç»è¿‡Reprogramming + LLM
num_patches = patches.shape[1]
llm_out = torch.randn(batch_size, num_vars, d_ff, num_patches, device=device)
print(f"3. LLMéšçŠ¶æ€: {llm_out.shape}")

# Step 4: WaveletHeadé¢„æµ‹
wavelet_head_pred = WaveletHead(
    n_vars=num_vars,
    d_model=d_ff,
    patch_nums=num_patches,
    pred_len=pred_len,
    level=level,
    wavelet=wavelet,
    head_dropout=0.1
).to(device)
final_pred = wavelet_head_pred(llm_out)
print(f"4. æœ€ç»ˆé¢„æµ‹: {final_pred.shape}")

print("\nâœ… ç«¯åˆ°ç«¯æµç¨‹æµ‹è¯•é€šè¿‡ï¼")

print("\n" + "=" * 80)
print("æµ‹è¯•5: ä¸åŒé¢‘æ®µç‹¬ç«‹é¢„æµ‹éªŒè¯")
print("=" * 80)

# éªŒè¯WaveletHeadç¡®å®ä¸ºæ¯ä¸ªé¢‘æ®µç‹¬ç«‹é¢„æµ‹
print("\néªŒè¯é¢‘æ®µç‹¬ç«‹æ€§...")
print(f"WaveletHeadæœ‰ {wavelet_head_pred.num_bands} ä¸ªç‹¬ç«‹çš„æŠ•å½±å±‚")

# æ£€æŸ¥æ¯ä¸ªæŠ•å½±å±‚çš„å‚æ•°
for i, proj in enumerate(wavelet_head_pred.band_projections):
    num_params = sum(p.numel() for p in proj.parameters())
    print(f"  é¢‘æ®µ{i} (band_{i}): {num_params:,} å‚æ•°")

print("\né¢‘æ®µå«ä¹‰:")
print("  é¢‘æ®µ0: cA3 - ä½é¢‘è¶‹åŠ¿ï¼ˆå…¨å±€æ¨¡å¼ï¼‰")
print("  é¢‘æ®µ1: cD3 - æœ€é«˜é¢‘ç»†èŠ‚")
print("  é¢‘æ®µ2: cD2 - ä¸­é¢‘ç»†èŠ‚")
print("  é¢‘æ®µ3: cD1 - ä½é¢‘ç»†èŠ‚")

print("\n" + "=" * 80)
print("âœ… æ‰€æœ‰æµ‹è¯•å®Œæˆï¼")
print("=" * 80)

print("\nğŸ‰ å°æ³¢åŸŸå¯¹ç§°æ¶æ„å®ç°æˆåŠŸï¼")
print("\nä½¿ç”¨æ–¹æ³•ï¼š")
print("åœ¨é…ç½®æ–‡ä»¶ä¸­æ·»åŠ :")
print("  configs.use_wavelet = True          # ä½¿ç”¨WaveletPatchEmbedding")
print("  configs.use_wavelet_head = True     # ä½¿ç”¨WaveletHeadè¾“å‡º")
print("  configs.wavelet = 'db4'             # å°æ³¢ç±»å‹")
print("  configs.swt_level = 3               # åˆ†è§£å±‚æ•°")
