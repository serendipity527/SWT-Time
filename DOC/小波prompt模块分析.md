# åŸºäºå°æ³¢å˜æ¢çš„åŠ¨æ€ Prompt è®¾è®¡åˆ†æ

## 1. å½“å‰ Prompt çš„å±€é™æ€§

### ç°æœ‰å®ç°å›é¡¾
```python
@/home/dmx_MT/LZF/project/SWT-Time/models/TimeLLM.py#236:244
```

### âŒ ç¼ºå¤±çš„å…³é”®ä¿¡æ¯

| ç»´åº¦ | ç°æœ‰ç‰¹å¾ | ç¼ºå¤±ä¿¡æ¯ |
|------|---------|---------|
| **ç»Ÿè®¡é‡** | âœ… min/max/median | âŒ å¤šå°ºåº¦ç»Ÿè®¡ï¼ˆä¸åŒé¢‘æ®µçš„åˆ†å¸ƒï¼‰ |
| **è¶‹åŠ¿** | âœ… æ•´ä½“è¶‹åŠ¿ï¼ˆupward/downwardï¼‰ | âŒ å¤šå°ºåº¦è¶‹åŠ¿ï¼ˆé•¿æœŸvsçŸ­æœŸï¼‰ |
| **å‘¨æœŸæ€§** | âœ… top-5 lagsï¼ˆæ—¶åŸŸè‡ªç›¸å…³ï¼‰ | âŒ é¢‘åŸŸèƒ½é‡åˆ†å¸ƒï¼ˆå“ªäº›é¢‘ç‡æœ€å¼ºï¼‰ |
| **æ³¢åŠ¨æ€§** | âŒ å®Œå…¨ç¼ºå¤± | âŒ é«˜é¢‘å™ªå£° vs ä½é¢‘å˜åŒ–çš„é‡åŒ– |
| **ç¨³å®šæ€§** | âŒ å®Œå…¨ç¼ºå¤± | âŒ åºåˆ—å¹³ç¨³æ€§æè¿° |
| **å¼‚å¸¸æ£€æµ‹** | âŒ å®Œå…¨ç¼ºå¤± | âŒ çªå˜ç‚¹ä½ç½®å’Œå¹…åº¦ |

### æ ¸å¿ƒé—®é¢˜
**å•ä¸€å°ºåº¦è§†è§’**: å½“å‰ Prompt å°†æ—¶é—´åºåˆ—è§†ä¸ºå•ä¸€ä¿¡å·ï¼Œæ— æ³•åŒºåˆ†ï¼š
- ğŸ“ˆ **è¶‹åŠ¿æ¼‚ç§»**ï¼ˆä½é¢‘ï¼‰vs **çŸ­æœŸæ³¢åŠ¨**ï¼ˆé«˜é¢‘ï¼‰
- ğŸ”Š **ä¿¡å·**ï¼ˆæœ‰æ„ä¹‰çš„æ¨¡å¼ï¼‰vs **å™ªå£°**ï¼ˆéšæœºæ‰°åŠ¨ï¼‰
- ğŸ“Š **ä¸»å¯¼æ¨¡å¼**ï¼ˆèƒ½é‡é›†ä¸­ï¼‰vs **æ¬¡è¦æˆåˆ†**ï¼ˆèƒ½é‡åˆ†æ•£ï¼‰

---

## 2. å°æ³¢å˜æ¢èƒ½æä¾›çš„é¢å¤–ä¿¡æ¯

### æ ¸å¿ƒä»·å€¼ï¼šå¤šå°ºåº¦é¢‘è°±åˆ†è§£

```
åŸå§‹åºåˆ— (T=512)
    â†“ å°æ³¢åˆ†è§£
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ cA3 (è¿‘ä¼¼)  â†’ é•¿æœŸè¶‹åŠ¿ (å‘¨æœŸ 64-âˆ) â”‚  
â”‚ cD3 (ç»†èŠ‚3) â†’ ä½é¢‘å‘¨æœŸ (å‘¨æœŸ 32-64) â”‚  
â”‚ cD2 (ç»†èŠ‚2) â†’ ä¸­é¢‘æ³¢åŠ¨ (å‘¨æœŸ 16-32) â”‚  
â”‚ cD1 (ç»†èŠ‚1) â†’ é«˜é¢‘å™ªå£° (å‘¨æœŸ 8-16)  â”‚  
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### å¯æå–çš„ 4 ç±»ç‰¹å¾

#### ğŸ”‹ é¢‘æ®µèƒ½é‡åˆ†å¸ƒ
```python
energy_ratio = [85%, 8%, 5%, 2%]  # [cA, cD3, cD2, cD1]
```
**è½¬åŒ–ä¸º Prompt**:
- "85% energy in low-frequency trend, minimal noise (2%)"
- "Evenly distributed energy across scales (multi-scale pattern)"

#### ğŸ“ˆ å¤šå°ºåº¦è¶‹åŠ¿ä¸€è‡´æ€§
```python
trends = {
    'cA3': +120,   # é•¿æœŸä¸Šå‡
    'cD3': -5,     # ä½é¢‘å°å¹…ä¸‹é™
    'cD2': +15,    # ä¸­é¢‘ä¸Šå‡
    'cD1': -2      # é«˜é¢‘æ¥è¿‘å¹³ç¨³
}
```
**è½¬åŒ–ä¸º Prompt**:
- "Consistent upward trend across all scales"
- "Long-term upward but short-term downward correction"

#### ğŸŒŠ æ³¢åŠ¨æ€§å±‚çº§
```python
volatilities = [0.1, 0.3, 0.8, 1.2]  # [cA, cD3, cD2, cD1]
```
**è½¬åŒ–ä¸º Prompt**:
- "Stable trend with high short-term volatility"
- "Low noise level, predictable pattern"

#### âš¡ ä¿¡å·å¤æ‚åº¦
```python
entropy = -Î£(p * log(p))  # åŸºäºèƒ½é‡åˆ†å¸ƒ
dominant_band = argmax(energy_ratio)
```
**è½¬åŒ–ä¸º Prompt**:
- "Simple trend-dominated pattern (low entropy)"
- "Complex multi-scale dynamics (high entropy)"

---

## 3. ä½¿ç”¨ DWT è¿˜æ˜¯ SWTï¼Ÿ

### ğŸ† æ¨èï¼š**DWT ç”¨äº Prompt ç”Ÿæˆ**

### å†³ç­–çŸ©é˜µ

| è¯„ä¼°ç»´åº¦ | SWT | DWT | Prompt éœ€æ±‚ | ä¼˜èƒœè€… |
|---------|-----|-----|------------|--------|
| **è®¡ç®—é€Ÿåº¦** | ~1.5ms | ~0.5ms | âš¡ å¿«é€Ÿ | **DWT** |
| **å†…å­˜å ç”¨** | 1.8MB | 0.86MB | ğŸ’¾ èŠ‚çœ | **DWT** |
| **å¹³ç§»ä¸å˜æ€§** | âœ… æœ‰ | âŒ æ—  | ğŸ¤· ä¸é‡è¦ï¼ˆç»Ÿè®¡é‡æœ¬èº«ç¨³å®šï¼‰ | å¹³å±€ |
| **æ—¶é—´å¯¹é½** | âœ… ç­‰é•¿ | âŒ ä¸‹é‡‡æ · | âŒ ä¸éœ€è¦ï¼ˆåªè¦å…¨å±€ç»Ÿè®¡ï¼‰ | **DWT** |
| **ä¿¡æ¯å……åˆ†æ€§** | å®Œæ•´ | å®Œæ•´ | âœ… ç»Ÿè®¡é‡å……åˆ† | å¹³å±€ |
| **ä»£ç ç®€æ´** | è¾ƒå¤æ‚ | ç®€æ´ | âœ… æ˜“ç»´æŠ¤ | **DWT** |

### æ ¸å¿ƒç†ç”±

#### âœ… DWT ä¼˜åŠ¿
```python
# é€Ÿåº¦å¯¹æ¯”ï¼ˆlevel=3, T=512ï¼‰
SWT è¾“å‡º: 512Ã—4 = 2048 å…ƒç´  â†’ ç»Ÿè®¡é‡
DWT è¾“å‡º: 512+256+128+64 = 960 å…ƒç´  â†’ ç»Ÿè®¡é‡

# ä¿¡æ¯ç­‰ä»·æ€§
mean(SWT_cD1) â‰ˆ mean(DWT_cD1)
energy(SWT_cD1) â‰ˆ energy(DWT_cD1)
# ç»Ÿè®¡ç‰¹å¾åœ¨ä¸¤ç§å˜æ¢ä¸‹é«˜åº¦ä¸€è‡´
```

#### âŒ SWT æ— é¢å¤–æ”¶ç›Š
```python
# Prompt ä¸éœ€è¦é€ç‚¹å¯¹é½
"High-frequency energy: 15%"  # âœ… DWT è¶³å¤Ÿ
"High-frequency energy at t=237: 0.8"  # âŒ è¿‡åº¦ç»†èŠ‚ï¼ŒPrompt ä¸éœ€è¦
```

### æ¶æ„åˆ†å·¥

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          WaveletPatchEmbedding              â”‚
â”‚  âœ… ä½¿ç”¨ SWTï¼ˆä¿ç•™æ—¶é—´å±€éƒ¨æ€§ï¼Œpatchå¯¹é½ï¼‰    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          Prompt ç”Ÿæˆæ¨¡å—                     â”‚
â”‚  âœ… ä½¿ç”¨ DWTï¼ˆå¿«é€Ÿæå–å…¨å±€ç»Ÿè®¡ç‰¹å¾ï¼‰         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
         [Prompt + Patches] â†’ LLM
```

**äº’è¡¥è€Œéé‡å¤**ï¼š
- **SWT Embedding**: å±€éƒ¨å¤šå°ºåº¦ç‰¹å¾ â†’ æ•è·ç»†ç²’åº¦æ¨¡å¼
- **DWT Prompt**: å…¨å±€é¢‘è°±æ¦‚è§ˆ â†’ æä¾›è¯­ä¹‰ä¸Šä¸‹æ–‡

### æ€§èƒ½æå‡é¢„ä¼°

| æŒ‡æ ‡ | SWT æ–¹æ¡ˆ | DWT æ–¹æ¡ˆ | æå‡ |
|------|---------|---------|------|
| å•æ¬¡ forward æ—¶é—´ | +1.5ms | +0.5ms | **èŠ‚çœ 1ms** |
| è®­ç»ƒ 100K iter | +150s | +50s | **èŠ‚çœ 1.7åˆ†é’Ÿ** |
| ä¸´æ—¶å†…å­˜å ç”¨ | 1.8MB/batch | 0.86MB/batch | **èŠ‚çœ 52%** |
| ä»£ç å¤æ‚åº¦ | éœ€å¤„ç†ç»´åº¦ | å•è¡Œè°ƒç”¨ | **æ›´ç®€æ´** |

---

## å®æ–½å»ºè®®

### æ¨èæ–¹æ¡ˆï¼šDWT + æ–¹æ¡ˆAï¼ˆé¢‘æ®µç»Ÿè®¡å¢å¼ºï¼‰

```python
def calculate_wavelet_prompt_features(self, x_enc):
    """ä½¿ç”¨ DWT æå– prompt ç‰¹å¾ï¼ˆé«˜æ•ˆç‰ˆæœ¬ï¼‰"""
    import ptwt
    
    B, N, T = x_enc.shape
    x_reshaped = x_enc.reshape(B * N, 1, T).float()
    
    # DWT åˆ†è§£ï¼ˆå¿«é€Ÿï¼‰
    coeffs = ptwt.wavedec(x_reshaped, 'db4', level=3, mode='reflect')
    # è¿”å› [cA3, cD3, cD2, cD1]
    
    # æå–æ ¸å¿ƒç‰¹å¾ï¼ˆ3ä¸ªï¼‰
    features = {
        'energy_ratio': self._calc_energy_ratio(coeffs),      # é¢‘æ®µèƒ½é‡å æ¯”
        'volatility': self._calc_volatility(coeffs),          # å„é¢‘æ®µæ³¢åŠ¨æ€§
        'trend_consistency': self._calc_trend_direction(coeffs)  # å¤šå°ºåº¦è¶‹åŠ¿
    }
    
    return features
```

### æ ¸å¿ƒä¼˜åŠ¿
- âš¡ **é«˜æ•ˆ**: DWT æ¯” SWT å¿« 3 å€
- ğŸ“Š **å……åˆ†**: ç»Ÿè®¡ç‰¹å¾å®Œæ•´ï¼Œæ— ä¿¡æ¯æŸå¤±
- ğŸ¯ **ä¸“æ³¨**: åªæå– Prompt éœ€è¦çš„å…¨å±€ç‰¹å¾
- ğŸ”§ **ç®€æ´**: ä»£ç æ¸…æ™°ï¼Œæ˜“äºç»´æŠ¤å’Œæ‰©å±•

---

**æœ€ç»ˆç­”æ¡ˆï¼šä½¿ç”¨ DWT ç”¨äº Prompt ç”Ÿæˆï¼Œä¿ç•™ SWT ç”¨äº Embeddingï¼** ğŸ¯




## ä¸€ã€åŸç‰ˆ Prompt è®¾è®¡æ€è·¯åˆ†æ

### 1.1 è®¾è®¡æ¶æ„

```python
@/home/dmx_MT/LZF/project/SWT-Time/models/TimeLLM.py#230:247
```

### 1.2 åŸç‰ˆè®¾è®¡å“²å­¦

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            åŸç‰ˆ Prompt è®¾è®¡çš„ä¸‰å±‚ç»“æ„                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                         â”‚
â”‚  Layer 1: ä»»åŠ¡ä¸Šä¸‹æ–‡ (Task Context)                      â”‚
â”‚  â”œâ”€ Dataset description (é¢†åŸŸçŸ¥è¯†)                       â”‚
â”‚  â””â”€ Task description (è¾“å…¥/è¾“å‡ºé•¿åº¦)                      â”‚
â”‚                                                         â”‚
â”‚  Layer 2: ç»Ÿè®¡ç‰¹å¾ (Statistical Features)                â”‚
â”‚  â”œâ”€ Min/Max/Median (æ•°å€¼èŒƒå›´)                            â”‚
â”‚  â””â”€ Trend direction (æ•´ä½“è¶‹åŠ¿)                           â”‚
â”‚                                                         â”‚
â”‚  Layer 3: æ—¶åŸŸæ¨¡å¼ (Temporal Patterns)                   â”‚
â”‚  â””â”€ Top-5 lags (å‘¨æœŸæ€§ç‰¹å¾)                              â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.3 ç‰¹å¾æå–é€»è¾‘

#### **ç‰¹å¾1: åŸºç¡€ç»Ÿè®¡é‡** (L224-226)
```python
min_values = torch.min(x_enc, dim=1)[0]      # æœ€å°å€¼
max_values = torch.max(x_enc, dim=1)[0]      # æœ€å¤§å€¼
medians = torch.median(x_enc, dim=1).values  # ä¸­ä½æ•°
```

**è®¾è®¡æ„å›¾**: 
- å‘Šè¯‰ LLM æ•°å€¼å°ºåº¦ï¼ˆé‡çº²æ„ŸçŸ¥ï¼‰
- å¸®åŠ©åˆ¤æ–­æ˜¯å¦å­˜åœ¨æç«¯å€¼

#### **ç‰¹å¾2: è¶‹åŠ¿æ–¹å‘** (L228)
```python
trends = x_enc.diff(dim=1).sum(dim=1)
# æ­£å€¼ â†’ upward, è´Ÿå€¼ â†’ downward
```

**è®¾è®¡æ„å›¾**:
- æä¾›ä¸€é˜¶å¯¼æ•°çš„å…¨å±€èšåˆ
- ç®€å•çš„äºŒåˆ†ç±»è¶‹åŠ¿æ ‡ç­¾

#### **ç‰¹å¾3: è‡ªç›¸å…³æ»å** (L227, L274-281)
```python
def calcute_lags(self, x_enc):
    # FFT è‡ªç›¸å…³åˆ†æ
    q_fft = torch.fft.rfft(x_enc, dim=-1)
    corr = torch.fft.irfft(q_fft * torch.conj(q_fft), dim=-1)
    _, lags = torch.topk(corr.mean(dim=1), self.top_k, dim=-1)
    return lags
```

**è®¾è®¡æ„å›¾**:
- é¢‘åŸŸåˆ†ææ‰¾åˆ°ä¸»å¯¼å‘¨æœŸ
- ç¼–ç æ—¶é—´åºåˆ—çš„å‘¨æœŸæ€§ç»“æ„

### 1.4 Prompt æ¨¡æ¿ç»“æ„

```python
prompt = f"""
<|start_prompt|>
Dataset description: {self.description}
Task description: forecast the next {pred_len} steps given the previous {seq_len} steps information; 
Input statistics: 
    min value {min_val}, 
    max value {max_val}, 
    median value {median_val}, 
    the trend of input is {'upward' if trend > 0 else 'downward'}, 
    top 5 lags are : {lags}
<|<end_prompt>|>
"""
```

### 1.5 åŸç‰ˆè®¾è®¡çš„ä¼˜ç¼ºç‚¹

| ç»´åº¦ | âœ… ä¼˜ç‚¹ | âŒ ç¼ºç‚¹ |
|------|--------|--------|
| **ç®€æ´æ€§** | æ¨¡æ¿å›ºå®šï¼Œæ˜“äºç†è§£ | ä¿¡æ¯å¯†åº¦ä½ |
| **æ•°å€¼ç‰¹å¾** | Min/Max/Median æ¸…æ™° | å•ä¸€å°ºåº¦ï¼Œæœªåˆ†ç¦»å™ªå£°å’Œä¿¡å· |
| **è¶‹åŠ¿æè¿°** | äºŒå…ƒæ ‡ç­¾ç®€å• | è¿‡äºç²—ç³™ï¼Œå¿½ç•¥å¤šå°ºåº¦è¶‹åŠ¿ |
| **å‘¨æœŸæ€§** | Top-5 lags æœ‰æ•ˆ | æ—¶åŸŸæ–¹æ³•ï¼Œæœªç›´æ¥é‡åŒ–é¢‘æ®µèƒ½é‡ |
| **å™ªå£°æ„ŸçŸ¥** | **å®Œå…¨ç¼ºå¤±** | æ— æ³•å‘ŠçŸ¥ LLM é¢„æµ‹éš¾åº¦ |
| **æ¨¡å¼ç±»å‹** | **å®Œå…¨ç¼ºå¤±** | æ— æ³•åŒºåˆ†å¹³æ»‘è¶‹åŠ¿ vs å¤æ‚æŒ¯è¡ |

---

## äºŒã€åŸºäº DWT çš„ Prompt è®¾è®¡æ–¹æ¡ˆ

### æ–¹æ¡ˆ A: æ¸è¿›å¼å¢å¼ºï¼ˆä¿å®ˆæ–¹æ¡ˆï¼‰

**è®¾è®¡æ€è·¯**: åœ¨åŸç‰ˆåŸºç¡€ä¸Š**è¿½åŠ **å°æ³¢ç‰¹å¾ï¼Œä¿æŒå…¼å®¹æ€§

#### A.1 æ¶æ„è®¾è®¡

```
åŸç‰ˆç‰¹å¾ (ä¿ç•™)
    â”‚
    â”œâ”€ Min/Max/Median
    â”œâ”€ Trend direction  
    â””â”€ Top-5 lags
    
    â†“ æ–°å¢
    
DWT å°æ³¢ç‰¹å¾ (è¿½åŠ )
    â”‚
    â”œâ”€ Energy distribution (é¢‘æ®µèƒ½é‡å æ¯”)
    â”œâ”€ Dominant frequency band (ä¸»å¯¼é¢‘æ®µ)
    â””â”€ Noise level (å™ªå£°æ°´å¹³)
```

#### A.2 ä»£ç å®ç°

```python
def calculate_wavelet_features_A(self, x_enc):
    """æ–¹æ¡ˆA: æ¸è¿›å¼å¢å¼º"""
    B, N, T = x_enc.shape
    x_reshaped = x_enc.reshape(B * N, 1, T).float()
    
    # DWT åˆ†è§£ (level=3)
    coeffs = ptwt.wavedec(x_reshaped, 'db4', level=3, mode='reflect')
    # coeffs = [cA3, cD3, cD2, cD1]
    
    # ç‰¹å¾1: é¢‘æ®µèƒ½é‡å æ¯”
    energies = [torch.sum(c**2, dim=-1) for c in coeffs]
    total_energy = sum(energies)
    energy_ratio = [(e / total_energy * 100).mean().item() for e in energies]
    # è¿”å›: [85.2, 8.3, 4.5, 2.0] (ç™¾åˆ†æ¯”)
    
    # ç‰¹å¾2: ä¸»å¯¼é¢‘æ®µ
    dominant_idx = torch.argmax(torch.stack(energies, dim=0), dim=0)
    dominant_band = dominant_idx.mode().values.item()  # ä¼—æ•°
    band_names = ['trend', 'low-freq', 'mid-freq', 'high-freq']
    
    # ç‰¹å¾3: å™ªå£°æ°´å¹³ (é«˜é¢‘èƒ½é‡å æ¯”)
    noise_level = energy_ratio[-1]  # cD1 èƒ½é‡å æ¯”
    
    return {
        'energy_ratio': energy_ratio,
        'dominant_band': band_names[dominant_band],
        'noise_level': noise_level
    }

def build_prompt_A(self, x_enc, ...):
    """æ„å»ºæ–¹æ¡ˆAçš„prompt"""
    # åŸç‰ˆç‰¹å¾ (ä¿ç•™)
    min_val, max_val, median = ...
    trend = 'upward' if ... else 'downward'
    lags = ...
    
    # æ–°å¢: DWTç‰¹å¾
    wavelet_feats = self.calculate_wavelet_features_A(x_enc)
    
    prompt = f"""
<|start_prompt|>
Dataset description: {self.description}
Task: forecast next {self.pred_len} steps from {self.seq_len} steps
Input statistics: min={min_val}, max={max_val}, median={median}, trend={trend}
Frequency analysis: top 5 lags are {lags}
Wavelet analysis: 
    - Dominant pattern: {wavelet_feats['dominant_band']}
    - Energy distribution: trend {wavelet_feats['energy_ratio'][0]:.1f}%, noise {wavelet_feats['noise_level']:.1f}%
    - Signal quality: {'clean' if wavelet_feats['noise_level'] < 5 else 'noisy'}
<|<end_prompt>|>
"""
    return prompt
```

#### A.3 ç¤ºä¾‹è¾“å‡º

```
åŸç‰ˆ:
min=-1.2, max=2.5, median=0.3, trend=upward, lags=[24,48,96,168,336]

æ–¹æ¡ˆA:
min=-1.2, max=2.5, median=0.3, trend=upward, lags=[24,48,96,168,336]
Wavelet: dominant=trend, energy=[85.2%, 8.3%, 4.5%, 2.0%], quality=clean
```

**ä¼˜ç‚¹**: 
- âœ… å‘åå…¼å®¹ï¼Œé£é™©ä½
- âœ… token å¢åŠ å°‘ (~15 tokens)
- âœ… æ·»åŠ é¢‘åŸŸè§†è§’

**ç¼ºç‚¹**:
- âŒ ä¿¡æ¯å†—ä½™ï¼ˆtrend direction ä¸ energy é‡å¤ï¼‰
- âŒ æœªå……åˆ†åˆ©ç”¨å°æ³¢å¤šå°ºåº¦ç‰¹æ€§

---

### æ–¹æ¡ˆ B: é¢‘æ®µè¯­ä¹‰åŒ–ï¼ˆå¹³è¡¡æ–¹æ¡ˆï¼‰â­

**è®¾è®¡æ€è·¯**: å°†å°æ³¢ç‰¹å¾è½¬åŒ–ä¸º**è‡ªç„¶è¯­è¨€æè¿°**ï¼Œæ›¿æ¢éƒ¨åˆ†åŸç‰ˆç‰¹å¾

#### B.1 æ¶æ„è®¾è®¡

```
æ›¿æ¢å¼è®¾è®¡
    â”‚
åŸç‰ˆä¿ç•™                         åŸç‰ˆæ›¿æ¢
â”œâ”€ Min/Max/Median      â†’      â”œâ”€ Multi-scale statistics
â”œâ”€ Trend (ç®€å•)        â†’      â”œâ”€ Multi-scale trend consistency
â””â”€ Top-5 lags (ä¿ç•™)           â””â”€ Frequency pattern type
```

#### B.2 ä»£ç å®ç°

```python
def calculate_wavelet_features_B(self, x_enc):
    """æ–¹æ¡ˆB: è¯­ä¹‰åŒ–ç‰¹å¾æå–"""
    B, N, T = x_enc.shape
    x_reshaped = x_enc.reshape(B * N, 1, T).float()
    
    coeffs = ptwt.wavedec(x_reshaped, 'db4', level=3, mode='reflect')
    # [cA3, cD3, cD2, cD1]
    
    # === ç‰¹å¾ç»„1: èƒ½é‡åˆ†å¸ƒ â†’ åºåˆ—ç±»å‹ ===
    energies = [torch.sum(c**2, dim=-1) for c in coeffs]
    total_energy = sum(energies)
    energy_ratio = torch.stack([e / total_energy for e in energies], dim=0)
    
    # è¯­ä¹‰åŒ–æ˜ å°„
    cA_ratio = energy_ratio[0].mean().item()
    if cA_ratio > 0.8:
        pattern_type = "smooth trend-dominated"
    elif cA_ratio > 0.6:
        pattern_type = "trend with moderate fluctuations"
    elif energy_ratio[1].mean().item() > 0.3:  # cD3 é«˜èƒ½é‡
        pattern_type = "strong periodic pattern"
    else:
        pattern_type = "complex multi-scale dynamics"
    
    # === ç‰¹å¾ç»„2: å¤šå°ºåº¦è¶‹åŠ¿ä¸€è‡´æ€§ ===
    trends = []
    for c in coeffs:
        # è®¡ç®—æ¯ä¸ªé¢‘æ®µçš„è¶‹åŠ¿æ–¹å‘
        diff = c[..., 1:] - c[..., :-1]
        trend_sum = diff.sum(dim=-1).mean().item()
        trends.append(trend_sum)
    
    # åˆ¤æ–­è¶‹åŠ¿ä¸€è‡´æ€§
    trends_sign = [1 if t > 0 else -1 for t in trends]
    if all(s == trends_sign[0] for s in trends_sign):
        trend_desc = f"consistently {'upward' if trends_sign[0] > 0 else 'downward'} across all scales"
    elif trends_sign[0] != trends_sign[-1]:
        trend_desc = f"long-term {'upward' if trends_sign[0]>0 else 'downward'} but short-term {'upward' if trends_sign[-1]>0 else 'downward'}"
    else:
        trend_desc = "mixed multi-scale behavior"
    
    # === ç‰¹å¾ç»„3: æ³¢åŠ¨æ€§å±‚çº§ ===
    volatilities = [torch.std(c).mean().item() for c in coeffs]
    high_freq_vol = volatilities[-1]  # cD1
    low_freq_vol = volatilities[0]    # cA3
    
    if high_freq_vol / low_freq_vol > 5:
        stability_desc = "stable trend with high short-term volatility"
    elif high_freq_vol / low_freq_vol < 1:
        stability_desc = "smooth and predictable pattern"
    else:
        stability_desc = "balanced volatility across scales"
    
    # === ç‰¹å¾ç»„4: é¢„æµ‹éš¾åº¦æŒ‡ç¤º ===
    noise_ratio = energy_ratio[-1].mean().item()  # cD1 èƒ½é‡å æ¯”
    if noise_ratio < 0.05:
        difficulty = "low difficulty (clean signal)"
    elif noise_ratio > 0.15:
        difficulty = "high difficulty (noisy)"
    else:
        difficulty = "moderate difficulty"
    
    return {
        'pattern_type': pattern_type,
        'trend_consistency': trend_desc,
        'stability': stability_desc,
        'difficulty': difficulty,
        'energy_pct': [e.mean().item() * 100 for e in energy_ratio]
    }

def build_prompt_B(self, x_enc, ...):
    """æ–¹æ¡ˆB: è¯­ä¹‰åŒ–prompt"""
    # ä¿ç•™çš„åŸç‰ˆç‰¹å¾
    min_val, max_val, median = ...
    lags = self.calcute_lags(x_enc)
    
    # DWTè¯­ä¹‰åŒ–ç‰¹å¾
    wf = self.calculate_wavelet_features_B(x_enc)
    
    prompt = f"""
<|start_prompt|>
Dataset: {self.description}
Task: forecast {self.pred_len} steps from {self.seq_len} historical steps
Input range: [{min_val:.2f}, {max_val:.2f}], median={median:.2f}
Pattern analysis:
  - Type: {wf['pattern_type']}
  - Trend: {wf['trend_consistency']}
  - Stability: {wf['stability']}
  - Forecast {wf['difficulty']}
  - Dominant periodicities: {lags[:3].tolist()}
<|<end_prompt>|>
"""
    return prompt
```

#### B.3 ç¤ºä¾‹è¾“å‡ºå¯¹æ¯”

```
åŸç‰ˆ Prompt (69 tokens):
Dataset: ETT | Task: forecast 96 from 512 | 
min=-1.2, max=2.5, median=0.3, trend=upward, 
lags=[24,48,96,168,336]

æ–¹æ¡ˆB Prompt (85 tokens):
Dataset: ETT | Task: forecast 96 from 512 |
Range: [-1.2, 2.5], median=0.3 |
Pattern: smooth trend-dominated |
Trend: consistently upward across all scales |
Stability: smooth and predictable |
Difficulty: low (clean signal) |
Periodicities: [24, 48, 96]
```

**ä¼˜ç‚¹**:
- âœ… ä¿¡æ¯å¯†åº¦é«˜ï¼Œè¯­ä¹‰æ¸…æ™°
- âœ… å¤šå°ºåº¦ç‰¹å¾å……åˆ†ä½“ç°
- âœ… é¢„æµ‹éš¾åº¦æŒ‡ç¤ºï¼ˆå¸®åŠ© LLM è°ƒæ•´ç½®ä¿¡åº¦ï¼‰
- âœ… token å¢åŠ å¯æ§ (+16 tokens)

**ç¼ºç‚¹**:
- âŒ éœ€è¦è°ƒä¼˜é˜ˆå€¼ï¼ˆ0.8, 0.6, 5ç­‰ï¼‰
- âŒ è¯­ä¹‰æ˜ å°„è§„åˆ™å¯èƒ½éœ€è¦æ•°æ®é›†å®šåˆ¶

---

### æ–¹æ¡ˆ C: æ•°å€¼ç²¾ç®€ + ç¬¦å·åŒ–ï¼ˆæ¿€è¿›æ–¹æ¡ˆï¼‰

**è®¾è®¡æ€è·¯**: ç”¨ç¬¦å·å’Œç¼©å†™æœ€å°åŒ– token æ•°é‡ï¼Œæœ€å¤§åŒ–ä¿¡æ¯å¯†åº¦

#### C.1 æ¶æ„è®¾è®¡

```
æç®€ç¬¦å·åŒ–
    â”‚
    â”œâ”€ ç»Ÿè®¡é‡: ç”¨åŒºé—´è¡¨ç¤º [min, max]@median
    â”œâ”€ èƒ½é‡: E=[85|8|5|2] (ç™¾åˆ†æ¯”)
    â”œâ”€ è¶‹åŠ¿: T=â†‘â†‘â†‘â†“ (å„é¢‘æ®µæ–¹å‘)
    â””â”€ éš¾åº¦: D=L/M/H (Low/Medium/High)
```

#### C.2 ä»£ç å®ç°

```python
def calculate_wavelet_features_C(self, x_enc):
    """æ–¹æ¡ˆC: ç¬¦å·åŒ–ç‰¹å¾"""
    B, N, T = x_enc.shape
    x_reshaped = x_enc.reshape(B * N, 1, T).float()
    
    coeffs = ptwt.wavedec(x_reshaped, 'db4', level=3, mode='reflect')
    
    # èƒ½é‡ç¬¦å·: E=[85|8|5|2]
    energies = [torch.sum(c**2, dim=-1) for c in coeffs]
    total = sum(energies)
    energy_str = '|'.join([f"{(e/total*100).mean().item():.0f}" for e in energies])
    
    # è¶‹åŠ¿ç¬¦å·: T=â†‘â†‘â†‘â†“
    trend_symbols = []
    for c in coeffs:
        trend = (c[..., 1:] - c[..., :-1]).sum(dim=-1).mean().item()
        if abs(trend) < 1e-3:
            trend_symbols.append('â†’')
        elif trend > 0:
            trend_symbols.append('â†‘')
        else:
            trend_symbols.append('â†“')
    trend_str = ''.join(trend_symbols)
    
    # éš¾åº¦ç¬¦å·: D=L/M/H
    noise_ratio = energies[-1] / total
    noise_pct = noise_ratio.mean().item() * 100
    if noise_pct < 5:
        difficulty = 'L'
    elif noise_pct < 15:
        difficulty = 'M'
    else:
        difficulty = 'H'
    
    # ä¸»å¯¼æ¨¡å¼: P=T/S/N (Trend/Seasonal/Noisy)
    if energies[0] / total > 0.8:
        pattern = 'T'
    elif energies[1] / total > 0.3:
        pattern = 'S'
    else:
        pattern = 'N'
    
    return {
        'energy': energy_str,
        'trend': trend_str,
        'difficulty': difficulty,
        'pattern': pattern
    }

def build_prompt_C(self, x_enc, ...):
    """æ–¹æ¡ˆC: ç¬¦å·åŒ–prompt"""
    min_val, max_val, median = ...
    lags = self.calcute_lags(x_enc)[:3]  # åªå–å‰3
    
    wf = self.calculate_wavelet_features_C(x_enc)
    
    prompt = f"""
<|start_prompt|>
Dataset: {self.description}
Task: forecast {self.pred_len} from {self.seq_len}
Stats: [{min_val:.2f},{max_val:.2f}]@{median:.2f}
Wavelet: E=[{wf['energy']}] T={wf['trend']} P={wf['pattern']} D={wf['difficulty']}
Lags: {lags.tolist()}
<|<end_prompt>|>
"""
    return prompt
```

#### C.3 ç¤ºä¾‹è¾“å‡º

```
åŸç‰ˆ (69 tokens):
Dataset: ETT | Task: forecast 96 from 512 | 
min=-1.2, max=2.5, median=0.3, trend=upward, lags=[24,48,96,168,336]

æ–¹æ¡ˆC (58 tokens, -16%):
Dataset: ETT | Task: forecast 96 from 512 |
Stats: [-1.2,2.5]@0.3 | Wavelet: E=[85|8|5|2] T=â†‘â†‘â†‘â†‘ P=T D=L | Lags:[24,48,96]
```

**ä¼˜ç‚¹**:
- âœ… Token æœ€å°‘ï¼Œæ¨ç†æœ€å¿«
- âœ… ä¿¡æ¯å¯†åº¦æé«˜
- âœ… ç¬¦å·ç›´è§‚ï¼ˆâ†‘â†“ æ¯” upward/downward æ›´æ¸…æ™°ï¼‰

**ç¼ºç‚¹**:
- âŒ å¯è¯»æ€§å·®ï¼Œéœ€è¦ LLM å­¦ä¹ ç¬¦å·ç³»ç»Ÿ
- âŒ å¯èƒ½å½±å“é¢„è®­ç»ƒ LLM çš„ç†è§£èƒ½åŠ›
- âŒ è°ƒè¯•å›°éš¾

---

### æ–¹æ¡ˆ D: è‡ªé€‚åº”è¯¦ç»†åº¦ï¼ˆåŠ¨æ€æ–¹æ¡ˆï¼‰

**è®¾è®¡æ€è·¯**: æ ¹æ®åºåˆ—å¤æ‚åº¦**åŠ¨æ€è°ƒæ•´** prompt è¯¦ç»†ç¨‹åº¦

#### D.1 æ ¸å¿ƒé€»è¾‘

```python
def adaptive_prompt_detail_level(self, wavelet_features):
    """æ ¹æ®ä¿¡å·å¤æ‚åº¦å†³å®špromptè¯¦ç»†åº¦"""
    
    # è®¡ç®—å¤æ‚åº¦å¾—åˆ†
    energy_entropy = -sum([p * np.log(p) for p in wavelet_features['energy_ratio'] if p > 0])
    noise_level = wavelet_features['energy_ratio'][-1]
    trend_consistency = all_same_sign(wavelet_features['trends'])
    
    complexity_score = (
        energy_entropy * 2.0 +          # èƒ½é‡åˆ†å¸ƒç†µ
        noise_level * 10.0 +            # å™ªå£°æƒé‡
        (0 if trend_consistency else 5) # è¶‹åŠ¿ä¸ä¸€è‡´æƒ©ç½š
    )
    
    # è‡ªé€‚åº”ç­–ç•¥
    if complexity_score < 3:
        # ç®€å•ä¿¡å· â†’ ç²¾ç®€prompt (æ–¹æ¡ˆC)
        return 'minimal'
    elif complexity_score < 8:
        # ä¸­ç­‰å¤æ‚ â†’ æ ‡å‡†prompt (æ–¹æ¡ˆA)
        return 'standard'
    else:
        # é«˜å¤æ‚åº¦ â†’ è¯¦ç»†prompt (æ–¹æ¡ˆB)
        return 'detailed'

def build_prompt_D(self, x_enc, ...):
    """è‡ªé€‚åº”prompt"""
    wf = self.calculate_wavelet_features_B(x_enc)
    detail_level = self.adaptive_prompt_detail_level(wf)
    
    if detail_level == 'minimal':
        return self.build_prompt_C(x_enc, ...)  # ç¬¦å·åŒ–
    elif detail_level == 'standard':
        return self.build_prompt_A(x_enc, ...)  # æ¸è¿›å¼
    else:
        return self.build_prompt_B(x_enc, ...)  # è¯­ä¹‰åŒ–
```

**ä¼˜ç‚¹**:
- âœ… å¹³è¡¡ token æ•ˆç‡å’Œä¿¡æ¯é‡
- âœ… ç®€å•åºåˆ—èŠ‚çœè®¡ç®—ï¼Œå¤æ‚åºåˆ—æä¾›æ›´å¤šä¸Šä¸‹æ–‡

**ç¼ºç‚¹**:
- âŒ å®ç°å¤æ‚ï¼Œè°ƒè¯•å›°éš¾
- âŒ ä¸åŒæ ·æœ¬ prompt æ ¼å¼ä¸ä¸€è‡´

---

## ä¸‰ã€æ–¹æ¡ˆå¯¹æ¯”ä¸æ¨è

### 3.1 ç»¼åˆå¯¹æ¯”è¡¨

| æ–¹æ¡ˆ | Tokenæ•° | ä¿¡æ¯é‡ | å¯è¯»æ€§ | å®ç°éš¾åº¦ | LLMé€‚é…æ€§ | æ¨èåº¦ |
|------|---------|--------|--------|----------|-----------|--------|
| **åŸç‰ˆ** | 69 | â­â­ | â­â­â­â­ | âœ… å·²å®ç° | â­â­â­â­ | Baseline |
| **æ–¹æ¡ˆA** | 84 (+22%) | â­â­â­ | â­â­â­â­ | â­â­â­â­ | â­â­â­â­ | â­â­â­ |
| **æ–¹æ¡ˆB** | 85 (+23%) | â­â­â­â­ | â­â­â­â­â­ | â­â­â­ | â­â­â­â­â­ | â­â­â­â­â­ |
| **æ–¹æ¡ˆC** | 58 (-16%) | â­â­â­ | â­â­ | â­â­â­â­ | â­â­ | â­â­ |
| **æ–¹æ¡ˆD** | 58-85 | â­â­â­â­ | â­â­â­ | â­â­ | â­â­â­ | â­â­â­ |

### 3.2 æœ€ç»ˆæ¨è

#### ğŸ† é¦–é€‰ï¼š**æ–¹æ¡ˆ Bï¼ˆé¢‘æ®µè¯­ä¹‰åŒ–ï¼‰**

**ç†ç”±**:
1. **ä¿¡æ¯å¯†åº¦æœ€ä¼˜**: å¤šå°ºåº¦ç‰¹å¾å……åˆ†ä½“ç°ï¼Œé¢„æµ‹éš¾åº¦æŒ‡ç¤º
2. **LLM å‹å¥½**: è‡ªç„¶è¯­è¨€æè¿°ï¼Œç¬¦åˆé¢„è®­ç»ƒè¯­æ–™åˆ†å¸ƒ
3. **å®ç°å¯è¡Œ**: é˜ˆå€¼å¯é€šè¿‡éªŒè¯é›†è°ƒä¼˜
4. **Token å¯æ§**: +16 tokens åœ¨å¯æ¥å—èŒƒå›´å†…

#### ğŸ¥ˆ å¤‡é€‰ï¼š**æ–¹æ¡ˆ Aï¼ˆæ¸è¿›å¼å¢å¼ºï¼‰**

**é€‚ç”¨åœºæ™¯**: 
- å¿«é€ŸéªŒè¯å°æ³¢ç‰¹å¾ä»·å€¼
- ä¿å®ˆè¿­ä»£ï¼Œé™ä½é£é™©
- ä½œä¸ºæ–¹æ¡ˆBçš„å‰ç½®å®éªŒ

#### ğŸ¥‰ å®éªŒæ€§ï¼š**æ–¹æ¡ˆ Cï¼ˆç¬¦å·åŒ–ï¼‰**

**é€‚ç”¨åœºæ™¯**:
- Token é¢„ç®—æåº¦å—é™
- éœ€è¦ fine-tune LLM å­¦ä¹ ç¬¦å·ç³»ç»Ÿ
- ä½œä¸ºæ¶ˆèå®éªŒå¯¹æ¯”

---

## å››ã€å®æ–½è·¯çº¿å›¾

### é˜¶æ®µ 1: åŸºå‡†æµ‹è¯•ï¼ˆ1å¤©ï¼‰
```python
# åœ¨éªŒè¯é›†ä¸Šæµ‹è¯•åŸç‰ˆæ€§èƒ½
baseline_mse = evaluate(model, val_loader)
```

### é˜¶æ®µ 2: æ–¹æ¡ˆ A å¿«é€ŸéªŒè¯ï¼ˆ2å¤©ï¼‰
```python
# å®ç°æ–¹æ¡ˆAï¼Œæ·»åŠ 3ä¸ªæ ¸å¿ƒç‰¹å¾
# è¯„ä¼° MSE æ˜¯å¦æå‡
```

### é˜¶æ®µ 3: æ–¹æ¡ˆ B å®Œæ•´å®ç°ï¼ˆ3-4å¤©ï¼‰
```python
# å®ç°è¯­ä¹‰åŒ–æ˜ å°„
# åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šæµ‹è¯•
# è°ƒä¼˜é˜ˆå€¼å‚æ•°
```

### é˜¶æ®µ 4: æ¶ˆèå®éªŒï¼ˆ2å¤©ï¼‰
```python
# æµ‹è¯•å„ç‰¹å¾çš„ç‹¬ç«‹è´¡çŒ®
ablation_tests = {
    'baseline': åŸç‰ˆ,
    '+energy': ä»…æ·»åŠ èƒ½é‡åˆ†å¸ƒ,
    '+trend': ä»…æ·»åŠ å¤šå°ºåº¦è¶‹åŠ¿,
    '+stability': ä»…æ·»åŠ æ³¢åŠ¨æ€§,
    'full': æ–¹æ¡ˆBå®Œæ•´ç‰ˆ
}
```

---

**æˆ‘çš„å»ºè®®ï¼šå…ˆå®ç°æ–¹æ¡ˆBï¼Œå¦‚æœæ•ˆæœæ˜¾è‘—å†è€ƒè™‘æ–¹æ¡ˆAä½œä¸ºè½»é‡ç‰ˆæœ¬ï¼**

éœ€è¦æˆ‘å¼€å§‹ç¼–å†™æ–¹æ¡ˆBçš„å®Œæ•´ä»£ç å—ï¼Ÿ